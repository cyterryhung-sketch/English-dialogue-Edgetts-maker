import edge_tts
import asyncio
import os
import tkinter as tk
from tkinter import scrolledtext, messagebox
import threading # å¯¼å…¥ threading æ¨¡å—
import wave # ç”¨äºé™éŸ³æ–‡ä»¶ç”Ÿæˆ (å¦‚æœéœ€è¦åˆå¹¶çš„è¯ï¼Œä½†ç›®å‰æ˜¯ç”Ÿæˆå•ç‹¬æ–‡ä»¶)
import contextlib # ç”¨äºæ–‡ä»¶æ“ä½œ
import numpy as np
import tempfile
import re  # ç”¨äºå¤„ç† pause æ ‡è®°
# ä½¿ç”¨ librosa å’Œ soundfile æ¥å¤„ç†éŸ³é¢‘æ–‡ä»¶æ ¼å¼è½¬æ¢
try:
    import librosa
    import soundfile as sf
    AUDIO_PROCESSING_AVAILABLE = True
except ImportError:
    AUDIO_PROCESSING_AVAILABLE = False

# å°è¯•å¯¼å…¥éŸ³é¢‘æ’­æ”¾åº“
try:
    import pygame
    PYGAME_AVAILABLE = True
except ImportError:
    PYGAME_AVAILABLE = False

# å°è¯•å¯¼å…¥ playsound åº“ä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ
try:
    from playsound import playsound
    PLAYSOUND_AVAILABLE = True
except ImportError:
    PLAYSOUND_AVAILABLE = False

# å¯ç”¨çš„éŸ³è‰²åˆ—è¡¨ï¼ŒæŒ‰ç±»åˆ«åˆ†ç±»
available_voices = {
    "ç¾å¼è‹±è¯­-ç”·å£°": {
        "Andrew (ç¾å¼)": "en-US-AndrewNeural",
        "Brian (ç¾å¼)": "en-US-BrianNeural",
        "Christopher (ç¾å¼)": "en-US-ChristopherNeural",
        "Roger (ç¾å¼)": "en-US-RogerNeural",
        "Steffan (ç¾å¼)": "en-US-SteffanNeural",
        "Guy (ç¾å¼, é»˜è®¤)": "en-US-GuyNeural",
    },
    "ç¾å¼è‹±è¯­-å¥³å£°": {
        "Ana (ç¾å¼)": "en-US-AnaNeural",
        "Aria (ç¾å¼)": "en-US-AriaNeural",
        "Ava (ç¾å¼)": "en-US-AvaNeural",
        "Jenny (ç¾å¼, é»˜è®¤)": "en-US-JennyNeural",
        "Michelle (ç¾å¼)": "en-US-MichelleNeural",
    },
    "è‹±å¼è‹±è¯­-ç”·å£°": {
        "Libby (è‹±å¼)": "en-GB-LibbyNeural",
        "Ryan (è‹±å¼)": "en-GB-RyanNeural",
    },
    "è‹±å¼è‹±è¯­-å¥³å£°": {
        "Sonia (è‹±å¼)": "en-GB-SoniaNeural",
        "Maisie (è‹±å¼)": "en-GB-MaisieNeural",
    },
    # å¯ä»¥æ ¹æ®éœ€è¦æ·»åŠ æ›´å¤šåˆ†ç±»ï¼Œä¾‹å¦‚ç«¥å£°
}

def play_audio_file(file_path):
    """
    æ’­æ”¾éŸ³é¢‘æ–‡ä»¶ï¼Œå°è¯•å¤šç§æ’­æ”¾æ–¹æ³•
    :param file_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
    """
    # æ–¹æ³•1: ä½¿ç”¨ pygame æ’­æ”¾ï¼ˆå…ˆå°è¯•è½¬æ¢æ ¼å¼ï¼‰
    if PYGAME_AVAILABLE:
        try:
            # å…ˆå°è¯•è½¬æ¢éŸ³é¢‘æ ¼å¼
            converted_file = None
            if AUDIO_PROCESSING_AVAILABLE:
                # åˆ›å»ºä¸´æ—¶æ–‡ä»¶ç”¨äºè½¬æ¢åçš„éŸ³é¢‘
                with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp_file:
                    converted_file = tmp_file.name
                
                # ä½¿ç”¨ librosa è¯»å–å¹¶é‡æ–°ä¿å­˜ä¸ºæ ‡å‡†æ ¼å¼
                audio_data, sample_rate = librosa.load(file_path, sr=None)
                sf.write(converted_file, audio_data, sample_rate)
                
                # ä½¿ç”¨ pygame æ’­æ”¾è½¬æ¢åçš„æ–‡ä»¶
                pygame.mixer.init()
                pygame.mixer.music.load(converted_file)
                pygame.mixer.music.play()
                
                # ç­‰å¾…æ’­æ”¾å®Œæˆ
                while pygame.mixer.music.get_busy():
                    pygame.time.wait(100)
                
                pygame.mixer.quit()
                
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                try:
                    os.unlink(converted_file)
                except:
                    pass
                    
                return True
            else:
                # ç›´æ¥å°è¯•æ’­æ”¾
                pygame.mixer.init()
                pygame.mixer.music.load(file_path)
                pygame.mixer.music.play()
                
                # ç­‰å¾…æ’­æ”¾å®Œæˆ
                while pygame.mixer.music.get_busy():
                    pygame.time.wait(100)
                
                pygame.mixer.quit()
                return True
                
        except Exception as e:
            print(f"ä½¿ç”¨ pygame æ’­æ”¾éŸ³é¢‘æ–‡ä»¶æ—¶å‡ºé”™: {e}")
            try:
                pygame.mixer.quit()
            except:
                pass
    
    # æ–¹æ³•2: ä½¿ç”¨ playsound æ’­æ”¾
    if PLAYSOUND_AVAILABLE:
        try:
            playsound(file_path)
            return True
        except Exception as e:
            print(f"ä½¿ç”¨ playsound æ’­æ”¾éŸ³é¢‘æ–‡ä»¶æ—¶å‡ºé”™: {e}")
    
    # æ–¹æ³•3: ä½¿ç”¨ç³»ç»Ÿé»˜è®¤æ’­æ”¾å™¨
    try:
        import subprocess
        import platform
        
        system = platform.system()
        if system == "Windows":
            os.startfile(file_path)
        elif system == "Darwin":  # macOS
            subprocess.call(["afplay", file_path])
        else:  # Linux
            subprocess.call(["aplay", file_path])
        return True
    except Exception as e:
        print(f"ä½¿ç”¨ç³»ç»Ÿæ’­æ”¾å™¨æ’­æ”¾éŸ³é¢‘æ–‡ä»¶æ—¶å‡ºé”™: {e}")
    
    print("æ‰€æœ‰éŸ³é¢‘æ’­æ”¾æ–¹æ³•éƒ½å¤±è´¥äº†ï¼Œè¯·æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶æˆ–å®‰è£…éŸ³é¢‘æ’­æ”¾åº“")
    return False

def create_silence(duration, sample_rate=22050):
    """
    åˆ›å»ºæŒ‡å®šæ—¶é•¿çš„é™éŸ³éŸ³é¢‘æ–‡ä»¶
    :param duration: é™éŸ³æ—¶é•¿ï¼ˆç§’ï¼‰
    :param sample_rate: é‡‡æ ·ç‡
    :return: é™éŸ³éŸ³é¢‘æ–‡ä»¶è·¯å¾„
    """
    # åˆ›å»ºé™éŸ³numpyæ•°ç»„
    silence = np.zeros(int(sample_rate * duration), dtype=np.float32)
    
    # ä¿å­˜ä¸ºä¸´æ—¶æ–‡ä»¶
    with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp_file:
        temp_filename = tmp_file.name
    
    # ä½¿ç”¨soundfileä¿å­˜ï¼ˆå¦‚æœå¯ç”¨ï¼‰å¦åˆ™ä½¿ç”¨å…¶ä»–æ–¹æ³•
    if AUDIO_PROCESSING_AVAILABLE:
        sf.write(temp_filename, silence, sample_rate)
    else:
        # å¦‚æœæ²¡æœ‰soundfileï¼Œåˆ›å»ºä¸€ä¸ªéå¸¸çŸ­çš„é™éŸ³æ–‡ä»¶
        with wave.open(temp_filename, 'wb') as wav_file:
            wav_file.setnchannels(1)  # å•å£°é“
            wav_file.setsampwidth(2)   # 16ä½
            wav_file.setframerate(sample_rate)
            wav_file.writeframes(b'\x00' * int(sample_rate * duration * 2))
    
    return temp_filename

def merge_audio_files_with_librosa(file_list, output_filename):
    """
    ä½¿ç”¨ librosa åˆå¹¶å¤šä¸ªéŸ³é¢‘æ–‡ä»¶ä¸ºä¸€ä¸ªæ–‡ä»¶
    :param file_list: è¦åˆå¹¶çš„éŸ³é¢‘æ–‡ä»¶åˆ—è¡¨
    :param output_filename: è¾“å‡ºæ–‡ä»¶å
    """
    if not file_list:
        return False
    
    try:
        # åˆå§‹åŒ–ä¸€ä¸ªç©ºçš„éŸ³é¢‘æ•°ç»„
        combined_audio = np.array([], dtype=np.float32)
        sample_rate = None
        
        # ä¾æ¬¡è¯»å–å¹¶åˆå¹¶æ‰€æœ‰éŸ³é¢‘æ–‡ä»¶
        for filename in file_list:
            # ä½¿ç”¨ librosa è¯»å–éŸ³é¢‘æ–‡ä»¶
            audio_data, sr = librosa.load(filename, sr=None)
            
            # ä¿å­˜é‡‡æ ·ç‡ï¼ˆä½¿ç”¨ç¬¬ä¸€ä¸ªæ–‡ä»¶çš„é‡‡æ ·ç‡ï¼‰
            if sample_rate is None:
                sample_rate = sr
            
            # åˆå¹¶éŸ³é¢‘æ•°æ®
            combined_audio = np.concatenate([combined_audio, audio_data])
        
        # ä¿å­˜åˆå¹¶åçš„éŸ³é¢‘æ–‡ä»¶
        sf.write(output_filename, combined_audio, sample_rate)
        return True
    except Exception as e:
        print(f"ä½¿ç”¨ librosa åˆå¹¶éŸ³é¢‘æ–‡ä»¶æ—¶å‡ºé”™: {e}")
        return False

def merge_wav_files(file_list, output_filename):
    """
    åˆå¹¶å¤šä¸ª WAV æ–‡ä»¶ä¸ºä¸€ä¸ªæ–‡ä»¶
    :param file_list: è¦åˆå¹¶çš„ WAV æ–‡ä»¶åˆ—è¡¨
    :param output_filename: è¾“å‡ºæ–‡ä»¶å
    """
    if not file_list:
        return False
    
    try:
        # å°è¯•ä½¿ç”¨ librosa æ–¹æ³•åˆå¹¶ï¼ˆæ›´å¯é ï¼‰
        if AUDIO_PROCESSING_AVAILABLE:
            return merge_audio_files_with_librosa(file_list, output_filename)
        
        # å¦‚æœ librosa ä¸å¯ç”¨ï¼Œä½¿ç”¨ wave æ¨¡å—
        # è¯»å–ç¬¬ä¸€ä¸ªæ–‡ä»¶çš„å‚æ•°
        with wave.open(file_list[0], 'rb') as first_wav:
            params = first_wav.getparams()
            frames = first_wav.readframes(first_wav.getnframes())
        
        # åˆ›å»ºè¾“å‡ºæ–‡ä»¶
        with wave.open(output_filename, 'wb') as output_wav:
            output_wav.setparams(params)
            output_wav.writeframes(frames)
            
            # æ·»åŠ åç»­æ–‡ä»¶çš„å†…å®¹
            for filename in file_list[1:]:
                try:
                    with wave.open(filename, 'rb') as wav_file:
                        # ç¡®ä¿å‚æ•°åŒ¹é…
                        if wav_file.getparams()[:4] == params[:4]:  # æ£€æŸ¥å‰4ä¸ªå‚æ•°æ˜¯å¦ä¸€è‡´
                            frames = wav_file.readframes(wav_file.getnframes())
                            output_wav.writeframes(frames)
                        else:
                            print(f"è­¦å‘Š: {filename} å‚æ•°ä¸åŒ¹é…ï¼Œè·³è¿‡è¯¥æ–‡ä»¶")
                except Exception as e:
                    print(f"å¤„ç†æ–‡ä»¶ {filename} æ—¶å‡ºé”™: {e}")
                    continue
        
        return True
    except Exception as e:
        print(f"åˆå¹¶æ–‡ä»¶æ—¶å‡ºé”™: {e}")
        return False

def process_text_with_pause(text):
    """
    å¤„ç†æ–‡æœ¬ä¸­çš„[pause_X]æ ‡è®°ï¼Œå°†å…¶åˆ†ç¦»ä¸ºæ–‡æœ¬æ®µå’Œåœé¡¿æ—¶é•¿
    :param text: åŒ…å«pauseæ ‡è®°çš„æ–‡æœ¬
    :return: å¤„ç†åçš„æ–‡æœ¬æ®µåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ ä¸º(text_segment, pause_duration)
    """
    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æŸ¥æ‰¾[pause_X]æ ‡è®°
    pattern = r'\[pause_(\d+(?:\.\d+)?)\]'
    parts = re.split(pattern, text)
    
    result = []
    current_text = ""
    
    # ç¬¬ä¸€ä¸ªå…ƒç´ æ€»æ˜¯æ–‡æœ¬
    if parts[0]:
        current_text = parts[0]
    
    # å¤„ç†å‰©ä½™éƒ¨åˆ†
    for i in range(1, len(parts)):
        if i % 2 == 1:  # å¥‡æ•°ç´¢å¼•æ˜¯pauseçš„æ—¶é•¿
            pause_duration = float(parts[i])
            result.append((current_text, pause_duration))
            current_text = ""
        else:  # å¶æ•°ç´¢å¼•æ˜¯æ–‡æœ¬
            current_text = parts[i]
    
    # æ·»åŠ æœ€åä¸€æ®µæ–‡æœ¬ï¼ˆå¦‚æœæ²¡æœ‰ä»¥pauseç»“å°¾ï¼‰
    if current_text or len(result) == 0:
        result.append((current_text, 0.0))
    
    return result

def get_dialogue_from_gui(root, generate_callback):
    root.title("å¹¿ä¸œç¢§æ¡‚å›­å­¦æ ¡å°å­¦éƒ¨ä¸­æ–‡è½¬è‹±è¯­å¯¹è¯éŸ³é¢‘ç”Ÿæˆå™¨")
    root.geometry("800x700") # è°ƒæ•´çª—å£å¤§å°ä»¥é€‚åº”æ–°åŠŸèƒ½

    dialogue_data_storage = [] # ç”¨äºåœ¨ GUI å†…éƒ¨å­˜å‚¨è§£æåçš„å¯¹è¯æ•°æ®
    
    # å­˜å‚¨æ¯ä¸ªè¯´è¯è€…çš„éŸ³è‰²é€‰æ‹©
    speaker_voice_vars = {
        'A': tk.StringVar(value="Guy (ç¾å¼, é»˜è®¤)"), # é»˜è®¤å€¼
        'B': tk.StringVar(value="Jenny (ç¾å¼, é»˜è®¤)"), # é»˜è®¤å€¼
        'C': tk.StringVar(value="Christopher (ç¾å¼)"), # é»˜è®¤å€¼
        'D': tk.StringVar(value="Ana (ç¾å¼)"), # é»˜è®¤å€¼
    }
    
    # æ·»åŠ åˆå¹¶é€‰é¡¹å˜é‡
    merge_option_var = tk.BooleanVar(value=False)  # é»˜è®¤ä¸åˆå¹¶
    merged_filename_var = tk.StringVar(value="merged_output.wav")  # åˆå¹¶åçš„æ–‡ä»¶å

    # æ‰å¹³åŒ–å¯ç”¨çš„éŸ³è‰²åˆ—è¡¨ï¼Œç”¨äºä¸‹æ‹‰èœå•
    all_voice_names = []
    voice_id_map = {}
    for category, voices_in_category in available_voices.items():
        for name, voice_id in voices_in_category.items():
            all_voice_names.append(name)
            voice_id_map[name] = voice_id
    all_voice_names.sort()

    # çŠ¶æ€æ˜¾ç¤ºå˜é‡å’Œæ ‡ç­¾
    status_message = tk.StringVar(value="")
    filename_format_var = tk.StringVar(value="{index}_{speaker}.wav") # æ›´æ–°ï¼šç§»é™¤ text_preview

    def async_generate_wrapper(dialogue_list, status_callback, filename_format, root_instance, button):
        async def _run_generation():
            await generate_individual_audios(dialogue_list, status_callback, filename_format, root_instance)
            # ç”Ÿæˆå®Œæˆåï¼Œé‡æ–°å¯ç”¨æŒ‰é’®ï¼Œæ›´æ–°æœ€ç»ˆçŠ¶æ€
            root_instance.after(0, lambda: button.config(state=tk.NORMAL))
            root_instance.after(0, lambda: status_callback("å®Œæˆï¼æ‰€æœ‰éŸ³é¢‘æ–‡ä»¶å·²ç”Ÿæˆã€‚"))

        # é€‚é… Python 3.13: åœ¨æ–°çº¿ç¨‹ä¸­åˆ›å»ºå¹¶è¿è¡Œæ–°çš„äº‹ä»¶å¾ªç¯
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        loop.run_until_complete(_run_generation())
        loop.close()

    def preview_audio():
        """è¯•å¬åŠŸèƒ½ - ä½¿ç”¨å¯¹è¯å†…å®¹ä¸­æ‰€æœ‰è¯´è¯è€…çš„æ–‡æœ¬å’ŒéŸ³è‰²"""
        # è·å–å¯¹è¯å†…å®¹
        dialogue_text = text_area.get("1.0", tk.END).strip()
        lines = [L.strip() for L in dialogue_text.splitlines() if L.strip()]
        
        # è§£ææ‰€æœ‰è¯´è¯è€…åŠå…¶æ–‡æœ¬
        preview_texts = []
        for line in lines:
            if ":" in line:
                speaker_part, text_part = line.split(":", 1)
                speaker = speaker_part.strip().upper()
                text = text_part.strip()
                if text:  # ç¡®ä¿æ–‡æœ¬ä¸ä¸ºç©º
                    # ä½¿ç”¨å¯¹åº”è¯´è¯è€…çš„éŸ³è‰²è®¾ç½®
                    selected_voice_name = speaker_voice_vars[speaker].get()
                    voice_id = voice_id_map.get(selected_voice_name, "en-US-JennyNeural")
                    preview_texts.append((text, voice_id))
        
        # å¦‚æœåœ¨å¯¹è¯ä¸­æ²¡æœ‰æ‰¾åˆ°è¯´è¯è€…ï¼Œåˆ™ä½¿ç”¨é»˜è®¤æ–‡æœ¬
        if not preview_texts:
            preview_texts.append(("Hello, this is a preview.", "en-US-JennyNeural"))
            
        def run_preview():
            try:
                temp_files = []
                # ä¸ºæ¯ä¸ªè¯´è¯è€…åˆ›å»ºä¸´æ—¶éŸ³é¢‘æ–‡ä»¶
                for i, (text, voice_id) in enumerate(preview_texts):
                    # å¤„ç†æ–‡æœ¬ä¸­çš„pauseæ ‡è®°
                    text_segments = process_text_with_pause(text)
                    
                    segment_files = []
                    for segment_text, pause_duration in text_segments:
                        if segment_text:  # å¦‚æœæœ‰æ–‡æœ¬å†…å®¹
                            with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp_file:
                                temp_filename = tmp_file.name
                                segment_files.append(temp_filename)
                            
                            # ç”ŸæˆéŸ³é¢‘
                            async def generate_preview():
                                tts = edge_tts.Communicate(segment_text, voice=voice_id)
                                await tts.save(temp_filename)
                            
                            # åœ¨æ–°çº¿ç¨‹ä¸­è¿è¡Œå¼‚æ­¥å‡½æ•°
                            loop = asyncio.new_event_loop()
                            asyncio.set_event_loop(loop)
                            loop.run_until_complete(generate_preview())
                            loop.close()
                        
                        # å¦‚æœæœ‰åœé¡¿æ—¶é•¿ï¼Œæ·»åŠ é™éŸ³æ–‡ä»¶
                        if pause_duration > 0:
                            silence_file = create_silence(pause_duration)
                            segment_files.append(silence_file)
                    
                    # åˆå¹¶è¯¥è¯´è¯è€…çš„å¤šä¸ªç‰‡æ®µ
                    if len(segment_files) > 1:
                        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp_file:
                            merged_filename = tmp_file.name
                        
                        if merge_wav_files(segment_files, merged_filename):
                            temp_files.append(merged_filename)
                        else:
                            # å¦‚æœåˆå¹¶å¤±è´¥ï¼Œåªæ·»åŠ ç¬¬ä¸€ä¸ªæ–‡ä»¶
                            temp_files.append(segment_files[0])
                        
                        # æ¸…ç†ç‰‡æ®µæ–‡ä»¶
                        for segment_file in segment_files:
                            try:
                                os.unlink(segment_file)
                            except:
                                pass
                    elif len(segment_files) == 1:
                        temp_files.append(segment_files[0])
                
                # æ›´æ–°çŠ¶æ€
                status_message.set("æ­£åœ¨æ’­æ”¾è¯•å¬éŸ³é¢‘...")
                root.update()
                
                # æŒ‰é¡ºåºæ’­æ”¾æ‰€æœ‰éŸ³é¢‘
                all_played = True
                for temp_filename in temp_files:
                    if not play_audio_file(temp_filename):
                        all_played = False
                
                if all_played:
                    status_message.set("è¯•å¬å®Œæˆ")
                else:
                    status_message.set("è¯•å¬å®Œæˆï¼ˆéƒ¨åˆ†æ— æ³•æ’­æ”¾ï¼‰")
                
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                for temp_filename in temp_files:
                    try:
                        os.unlink(temp_filename)
                    except:
                        pass
                    
            except Exception as e:
                error_msg = f"è¯•å¬å¤±è´¥: {e}"
                print(error_msg)
                status_message.set(error_msg)
                messagebox.showerror("é”™è¯¯", error_msg)
        
        # åœ¨æ–°çº¿ç¨‹ä¸­è¿è¡Œè¯•å¬åŠŸèƒ½ï¼Œé¿å…é˜»å¡GUI
        threading.Thread(target=run_preview, daemon=True).start()

    def on_generate_button_click():
        nonlocal dialogue_data_storage

        # æ”¶é›†ç”¨æˆ·é€‰æ‹©çš„éŸ³è‰²
        selected_voices_map = {}
        for speaker, var in speaker_voice_vars.items():
            selected_voice_name = var.get()
            selected_voices_map[speaker] = voice_id_map.get(selected_voice_name, "en-US-JennyNeural") # é»˜è®¤å¥³å£°

        dialogue_text = text_area.get("1.0", tk.END).strip()
        if not dialogue_text:
            messagebox.showwarning("è¾“å…¥é”™è¯¯", "å¯¹è¯å†…å®¹ä¸èƒ½ä¸ºç©ºï¼")
            return

        lines = [L.strip() for L in dialogue_text.splitlines() if L.strip()]
        parsed_dialogue = []
        for line in lines:
            if ":" in line:
                speaker_part, text_part = line.split(":", 1)
                speaker = speaker_part.strip().upper()
                text = text_part.strip()
                if text: # ç¡®ä¿æ–‡æœ¬ä¸ä¸ºç©º
                    voice_id_for_speaker = selected_voices_map.get(speaker, "en-US-JennyNeural") # æœªé¢„è®¾çš„è§’è‰²ä½¿ç”¨é»˜è®¤å¥³å£°
                    parsed_dialogue.append((speaker, text, voice_id_for_speaker))  # æ·»åŠ éŸ³è‰²ID
                else:
                    print(f"âš ï¸ å¿½ç•¥ç©ºå¥å­å¯¹è¯è¡Œ: {line}")
            else:
                print(f"âš ï¸ å¿½ç•¥æ ¼å¼ä¸æ­£ç¡®çš„å¯¹è¯è¡Œ (ç¼ºå°‘å†’å·): {line}")
        
        if not parsed_dialogue:
            messagebox.showwarning("è¾“å…¥é”™è¯¯", "æ²¡æœ‰è§£æåˆ°æœ‰æ•ˆçš„å¯¹è¯å†…å®¹ã€‚è¯·ç¡®ä¿æ¯è¡Œæ ¼å¼ä¸º 'A: å¥å­' æˆ– 'B: å¥å­'ã€‚")
            return

        dialogue_data_storage = parsed_dialogue
        
        # è·å–ç”¨æˆ·å®šä¹‰çš„æ–‡ä»¶å‘½åæ ¼å¼
        custom_filename_format = filename_format_var.get()
        
        # è·å–åˆå¹¶é€‰é¡¹
        merge_option = merge_option_var.get()
        merged_filename = merged_filename_var.get()

        # å¼€å§‹ç”Ÿæˆï¼Œç¦ç”¨æŒ‰é’®ï¼Œæ›´æ–°çŠ¶æ€
        generate_button.config(state=tk.DISABLED)
        status_message.set("å¼€å§‹ç”ŸæˆéŸ³é¢‘...")
        # å°†è‡ªå®šä¹‰çš„æ–‡ä»¶å‘½åæ ¼å¼å’Œ root_instance ä¼ é€’ç»™ç”Ÿæˆå‡½æ•°
        generate_callback(dialogue_data_storage, status_message.set, custom_filename_format, generate_button, merge_option, merged_filename)

    # è¯•å¬åŠŸèƒ½åŒºåŸŸ
    preview_frame = tk.LabelFrame(root, text="è¯•å¬åŠŸèƒ½")
    preview_frame.pack(padx=10, pady=5, fill="x")
    
    # è¯•å¬æŒ‰é’®
    preview_control_frame = tk.Frame(preview_frame)
    preview_control_frame.pack(fill="x", padx=5, pady=2)
    tk.Label(preview_control_frame, text="è¯•å¬å¯¹è¯ä¸­æ‰€æœ‰è¯´è¯è€…:").pack(side=tk.LEFT)
    tk.Button(preview_control_frame, text="è¯•å¬", command=preview_audio, bg="lightblue").pack(side=tk.LEFT, padx=(5, 0))

    # éŸ³è‰²é€‰æ‹©åŒºåŸŸ
    voice_selection_frame = tk.LabelFrame(root, text="é€‰æ‹©è¯´è¯è€…éŸ³è‰² (A, B, C, D)")
    voice_selection_frame.pack(padx=10, pady=5, fill="x")

    # åˆ›å»ºä¸€ä¸ªæ¡†æ¶ç”¨äºå®¹çº³ä¸¤ä¸ªè¡Œ
    row_frame = tk.Frame(voice_selection_frame)
    row_frame.grid(row=0, column=0, padx=5, pady=2, sticky="w")

    # ç¬¬ä¸€è¡Œï¼šA å’Œ B çš„éŸ³è‰²é€‰æ‹©
    for i, speaker_char in enumerate(['A', 'B']):
        frame = tk.Frame(row_frame)
        frame.grid(row=0, column=i, padx=5, pady=2, sticky="w")
        
        tk.Label(frame, text=f"{speaker_char} çš„éŸ³è‰²:").pack(side=tk.LEFT)
        # ä¸‹æ‹‰èœå•
        option_menu = tk.OptionMenu(frame, speaker_voice_vars[speaker_char], *all_voice_names)
        option_menu.pack(side=tk.LEFT, fill="x", expand=True)

    # ç¬¬äºŒè¡Œï¼šC å’Œ D çš„éŸ³è‰²é€‰æ‹©
    row_frame2 = tk.Frame(voice_selection_frame)
    row_frame2.grid(row=1, column=0, padx=5, pady=2, sticky="w")

    for i, speaker_char in enumerate(['C', 'D']):
        frame = tk.Frame(row_frame2)
        frame.grid(row=0, column=i, padx=5, pady=2, sticky="w")
        
        tk.Label(frame, text=f"{speaker_char} çš„éŸ³è‰²:").pack(side=tk.LEFT)
        # ä¸‹æ‹‰èœå•
        option_menu = tk.OptionMenu(frame, speaker_voice_vars[speaker_char], *all_voice_names)
        option_menu.pack(side=tk.LEFT, fill="x", expand=True)
    
    # åˆå¹¶é€‰é¡¹åŒºåŸŸ
    merge_frame = tk.LabelFrame(root, text="åˆå¹¶é€‰é¡¹")
    merge_frame.pack(padx=10, pady=5, fill="x")
    
    tk.Checkbutton(merge_frame, text="åˆå¹¶æ‰€æœ‰éŸ³é¢‘ä¸ºä¸€ä¸ªæ–‡ä»¶", variable=merge_option_var).pack(anchor="w", padx=5, pady=2)
    
    merged_filename_frame = tk.Frame(merge_frame)
    merged_filename_frame.pack(fill="x", padx=5, pady=2)
    tk.Label(merged_filename_frame, text="åˆå¹¶åçš„æ–‡ä»¶å:").pack(side=tk.LEFT)
    tk.Entry(merged_filename_frame, textvariable=merged_filename_var, width=30).pack(side=tk.LEFT, fill="x", expand=True)

    # å¯¹è¯è¾“å…¥åŒºåŸŸ
    tk.Label(root, text="è¯·ç²˜è´´å¯¹è¯å†…å®¹ï¼ˆæ¯è¡Œä¸€ä¸ªå¯¹è¯æ¡ç›®ï¼Œä¾‹å¦‚ 'A: Hello'ï¼‰ï¼š").pack(pady=5)
    text_area = scrolledtext.ScrolledText(root, wrap=tk.WORD, width=70, height=15) 
    text_area.pack(padx=10, pady=5)
    text_area.insert("1.0", "A: ä¸€æ®µå¯¹è¯å†…å®¹\nB: å¦ä¸€æ®µå¯¹è¯å†…å®¹") # æ›´æ–°é»˜è®¤ç¤ºä¾‹å¯¹è¯

    # æ–‡ä»¶å‘½åæ ¼å¼è¾“å…¥æ¡†
    filename_format_frame = tk.LabelFrame(root, text="éŸ³é¢‘æ–‡ä»¶å‘½åæ ¼å¼")
    filename_format_frame.pack(padx=10, pady=5, fill="x")
    tk.Entry(filename_format_frame, textvariable=filename_format_var, width=60).pack(padx=5, pady=2, fill="x", expand=True)
    tk.Label(filename_format_frame, text="å¯ç”¨å ä½ç¬¦: {index}, {speaker}").pack(padx=5, pady=2, anchor="w") # æ›´æ–°è¯´æ˜

    # ç”ŸæˆæŒ‰é’®
    generate_button = tk.Button(root, text="ç”Ÿæˆå•ç‹¬éŸ³é¢‘æ–‡ä»¶", command=on_generate_button_click, font=("å¾®è½¯é›…é»‘", 12))
    generate_button.pack(pady=10)

    # çŠ¶æ€æ˜¾ç¤ºæ ‡ç­¾
    status_label = tk.Label(root, textvariable=status_message, fg="blue", font=("å¾®è½¯é›…é»‘", 10))
    status_label.pack(pady=5)


async def generate_individual_audios(dialogue_list, status_callback=None, filename_format="{index}_{speaker}.wav", root_instance=None, merge_files=False, merged_filename="merged_output.wav"):
    generated_files = []

    for i, (speaker, text, voice_id) in enumerate(dialogue_list):
        current_status = f"æ­£åœ¨ç”Ÿæˆç¬¬ {i + 1} / {len(dialogue_list)} æ®µéŸ³é¢‘ (è¯´è¯è€…: {speaker})"
        if status_callback and root_instance:
            root_instance.after(0, lambda msg=current_status: status_callback(msg)) # åœ¨ä¸»çº¿ç¨‹æ›´æ–° GUI

        # æ„å»ºæ–‡ä»¶å
        # ç§»é™¤äº† text_preview çš„ç”Ÿæˆ
        formatted_filename = filename_format.format(
            index=i + 1,
            speaker=speaker,
            # text_preview=text_preview # ç§»é™¤äº† text_preview
        )
        filename = formatted_filename # ä½¿ç”¨è‡ªå®šä¹‰æ ¼å¼çš„æ–‡ä»¶å

        print(f"âœ… {current_status} æ–‡ä»¶å: {filename} (æ–‡æœ¬: '{text[:30]}...', éŸ³è‰²: {voice_id})")
        try:
            # å¤„ç†æ–‡æœ¬ä¸­çš„pauseæ ‡è®°
            text_segments = process_text_with_pause(text)
            
            # å¦‚æœæœ‰pauseæ ‡è®°ï¼Œéœ€è¦ç”Ÿæˆå¤šä¸ªéŸ³é¢‘ç‰‡æ®µå¹¶åˆå¹¶
            if len(text_segments) > 1 or (len(text_segments) == 1 and text_segments[0][1] > 0):
                # ç”Ÿæˆå¤šä¸ªç‰‡æ®µ
                segment_files = []
                for segment_text, pause_duration in text_segments:
                    if segment_text:  # å¦‚æœæœ‰æ–‡æœ¬å†…å®¹
                        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp_file:
                            temp_filename = tmp_file.name
                        
                        # ç”ŸæˆéŸ³é¢‘
                        tts = edge_tts.Communicate(segment_text, voice=voice_id)
                        await tts.save(temp_filename)
                        segment_files.append(temp_filename)
                    
                    # å¦‚æœæœ‰åœé¡¿æ—¶é•¿ï¼Œæ·»åŠ é™éŸ³æ–‡ä»¶
                    if pause_duration > 0:
                        silence_file = create_silence(pause_duration)
                        segment_files.append(silence_file)
                
                # åˆå¹¶æ‰€æœ‰ç‰‡æ®µ
                if merge_wav_files(segment_files, filename):
                    print(f"âœ… éŸ³é¢‘æ–‡ä»¶ç”ŸæˆæˆåŠŸ: {filename}")
                    generated_files.append(filename)
                else:
                    print(f"âŒ åˆå¹¶éŸ³é¢‘æ–‡ä»¶å¤±è´¥: {filename}")
                
                # æ¸…ç†ä¸´æ—¶ç‰‡æ®µæ–‡ä»¶
                for segment_file in segment_files:
                    try:
                        os.unlink(segment_file)
                    except:
                        pass
            else:
                # æ²¡æœ‰pauseæ ‡è®°ï¼Œç›´æ¥ç”ŸæˆéŸ³é¢‘
                tts = edge_tts.Communicate(text, voice=voice_id)
                await tts.save(filename) # ä¿®æ­£ç¼©è¿›
                print(f"âœ… éŸ³é¢‘æ–‡ä»¶ç”ŸæˆæˆåŠŸ: {filename}")
                generated_files.append(filename)
        except Exception as e:
            error_msg = f"âŒ ç”ŸæˆéŸ³é¢‘æ–‡ä»¶å¤±è´¥ {filename}: {e}"
            print(error_msg)
            if status_callback and root_instance:
                root_instance.after(0, lambda msg=error_msg: status_callback(msg)) # åœ¨ä¸»çº¿ç¨‹æ›´æ–° GUI
            messagebox.showerror("é”™è¯¯", error_msg)
            # å¦‚æœä¸€ä¸ªæ–‡ä»¶ç”Ÿæˆå¤±è´¥ï¼Œæˆ‘ä»¬ä»ç„¶ç»§ç»­å°è¯•å…¶ä»–æ–‡ä»¶ï¼Œä½†ä¼šæ˜¾ç¤ºé”™è¯¯ã€‚

    # å¦‚æœé€‰æ‹©äº†åˆå¹¶é€‰é¡¹ï¼Œåˆ™åˆå¹¶æ‰€æœ‰éŸ³é¢‘æ–‡ä»¶
    if merge_files and generated_files:
        merge_status = f"æ­£åœ¨åˆå¹¶ {len(generated_files)} ä¸ªéŸ³é¢‘æ–‡ä»¶..."
        if status_callback and root_instance:
            root_instance.after(0, lambda msg=merge_status: status_callback(msg))
        print(merge_status)
        
        # ä½¿ç”¨è‡ªå®šä¹‰å‡½æ•°åˆå¹¶éŸ³é¢‘æ–‡ä»¶
        success = merge_wav_files(generated_files, merged_filename)
        
        if success:
            merge_success_msg = f"âœ… éŸ³é¢‘åˆå¹¶æˆåŠŸ: {merged_filename}"
            print(merge_success_msg)
            if status_callback and root_instance:
                root_instance.after(0, lambda msg=merge_success_msg: status_callback(msg))
        else:
            error_msg = "âŒ éŸ³é¢‘åˆå¹¶å¤±è´¥"
            print(error_msg)
            if status_callback and root_instance:
                root_instance.after(0, lambda msg=error_msg: status_callback(msg))
            messagebox.showerror("é”™è¯¯", "éŸ³é¢‘åˆå¹¶å¤±è´¥")

    if generated_files:
        final_msg = f"ğŸ‰ å·²ç”Ÿæˆ {len(generated_files)} ä¸ªå•ç‹¬çš„éŸ³é¢‘æ–‡ä»¶ã€‚\næ–‡ä»¶å°†ä¿å­˜åœ¨è„šæœ¬æ‰€åœ¨ç›®å½•ã€‚"
        if merge_files:
            final_msg += f"\nå·²åˆå¹¶ä¸ºæ–‡ä»¶: {merged_filename}"
        if status_callback and root_instance:
            root_instance.after(0, lambda msg=final_msg: status_callback(msg)) # åœ¨ä¸»çº¿ç¨‹æ›´æ–° GUI
        # messagebox.showinfo("å®Œæˆ", final_msg) # ç§»é™¤æç¤ºæ¡†
        print(final_msg)
    else:
        final_msg = "æç¤º", "æ²¡æœ‰ç”Ÿæˆä»»ä½•éŸ³é¢‘æ–‡ä»¶ã€‚"
        if status_callback and root_instance:
            root_instance.after(0, lambda msg=final_msg: status_callback(msg)) # åœ¨ä¸»çº¿ç¨‹æ›´æ–° GUI
        # messagebox.showwarning("æç¤º", "æ²¡æœ‰ç”Ÿæˆä»»ä½•éŸ³é¢‘æ–‡ä»¶ã€‚") # ç§»é™¤æç¤ºæ¡†

    return generated_files


async def main(): # ç¡®ä¿ main å‡½æ•°æ˜¯ async
    root = tk.Tk() # åœ¨ main å‡½æ•°ä¸­åˆ›å»º root

    def start_generation_from_gui(dialogue_list, status_set_callback, custom_filename_format, generate_button, merge_option=False, merged_filename="merged_output.wav"): # æ·»åŠ  generate_button å‚æ•°
        # å¯åŠ¨ç”Ÿæˆè¿‡ç¨‹ï¼Œç¡®ä¿åœ¨å•ç‹¬çº¿ç¨‹ä¸­è¿›è¡Œ
        def async_generate_wrapper(dialogue_list, status_callback, filename_format, root_instance, button, merge_files, merged_filename):
            async def _run_generation():
                await generate_individual_audios(dialogue_list, status_callback, filename_format, root_instance, merge_files, merged_filename)
                # ç”Ÿæˆå®Œæˆåï¼Œé‡æ–°å¯ç”¨æŒ‰é’®ï¼Œæ›´æ–°æœ€ç»ˆçŠ¶æ€
                root_instance.after(0, lambda: button.config(state=tk.NORMAL))
                root_instance.after(0, lambda: status_callback("å®Œæˆï¼æ‰€æœ‰éŸ³é¢‘æ–‡ä»¶å·²ç”Ÿæˆã€‚"))

            # é€‚é… Python 3.13: åœ¨æ–°çº¿ç¨‹ä¸­åˆ›å»ºå¹¶è¿è¡Œæ–°çš„äº‹ä»¶å¾ªç¯
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            loop.run_until_complete(_run_generation())
            loop.close()
        
        threading.Thread(target=async_generate_wrapper, args=(dialogue_list, status_set_callback, custom_filename_format, root, generate_button, merge_option, merged_filename)).start()

    get_dialogue_from_gui(root, start_generation_from_gui) # å°† root å’Œå›è°ƒå‡½æ•°ä¼ é€’ç»™ GUI é…ç½®å‡½æ•°
    root.mainloop() # è®© Tkinter GUI æŒç»­è¿è¡Œ
if __name__ == "__main__":
    # ç›´æ¥è¿è¡Œ main å‡½æ•°
    asyncio.run(main())